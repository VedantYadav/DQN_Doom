{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\conda\\conda\\envs\\dlwin36\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from vizdoom import *\n",
    "from collections import deque\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Setup environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_env():\n",
    "    game = DoomGame()\n",
    "    game.load_config(\"./ViZDoom-1.1.5pre-Win-Python36-x86_64/ViZDoom-1.1.5pre-Win-Python36-x86_64/vizdoom/scenarios/basic.cfg\")\n",
    "    game.set_doom_scenario_path(\"./ViZDoom-1.1.5pre-Win-Python36-x86_64/ViZDoom-1.1.5pre-Win-Python36-x86_64/vizdoom/scenarios/basic.wad\")\n",
    "#     game.init()\n",
    "    \n",
    "    shoot = [0,0,1]\n",
    "    left = [1,0,0]\n",
    "    right = [0,1,0]\n",
    "    possible_action = [shoot,left,right]\n",
    "    \n",
    "    return game,possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    game = DoomGame()\n",
    "    game.load_config(\"./ViZDoom-1.1.5pre-Win-Python36-x86_64/ViZDoom-1.1.5pre-Win-Python36-x86_64/vizdoom/scenarios/basic.cfg\")\n",
    "    game.set_doom_scenario_path(\"./ViZDoom-1.1.5pre-Win-Python36-x86_64/ViZDoom-1.1.5pre-Win-Python36-x86_64/vizdoom/scenarios/basic.wad\")\n",
    "#     game.set_mode(Mode.ASYNC_PLAYER)\n",
    "\n",
    "    game.init()\n",
    "\n",
    "    shoot = [0,0,1]\n",
    "    left = [1,0,0]\n",
    "    right = [0,1,0]\n",
    "\n",
    "    episodes = 10\n",
    "    for i in range(episodes):\n",
    "        game.new_episode()\n",
    "        while not game.is_episode_finished():\n",
    "            state = game.get_state()\n",
    "            img = state.screen_buffer\n",
    "            misc = state.game_variables\n",
    "            action = random.choice([shoot, left, right]) # A random agent\n",
    "            reward = game.make_action(action)\n",
    "            time.sleep(0.02) # Just to make it slower\n",
    "            \n",
    "            \n",
    "        print(\"Total reward: \" + str(game.get_total_reward()))\n",
    "    game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inp_data:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.que = deque(maxlen=4)\n",
    "    \n",
    "    def add(self,frame):\n",
    "        self.que.append(frame)\n",
    "        return np.stack(self.que,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    \n",
    "    frame = frame.mean(axis=0,dtype = np.int)\n",
    "    crop_frame = frame[30:-10,30:-30]\n",
    "    frame = crop_frame/255\n",
    "    return transform.resize(frame,[84,84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgsize = [84,84,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dqn:\n",
    "    \n",
    "    def __init__(self):\n",
    "        with tf.variable_scope(\"dqn_var\")\n",
    "            self._input = tf.placeholder(dtype=tf.float32,shape=[None,imgsize[0],imgsize[1],imgsize[2]],name=\"input\")\n",
    "            self._output = tf.placeholder(dtype=tf.float32,shape=[None,3],name=\"output\")\n",
    "            \n",
    "            self._conv1 = tf.layers.conv2d(self._input,\n",
    "                                     filters=32,\n",
    "                                     kernel_size=[8,8],\n",
    "                                     strides=[4,4],\n",
    "                                     padding=\"VALID\"\n",
    "                                     kernel_initializer=tf.initializers.contrib.layers.xavier_initializer_conv2d, \n",
    "                                     name=\"conv1\")\n",
    "            \n",
    "            self._conv1_batch = tf.layers.batch_normalization(self._conv1,trainable=True,name=\"b_conv1\")\n",
    "            self._conv1_out = tf.nn.elu(self._conv1_batch,name = \"e_conv1\")\n",
    "            \n",
    "            self._conv2 = tf.layers.conv2d(self._conv1_out,\n",
    "                                     filters=64,\n",
    "                                     kernel_size=[4,4],\n",
    "                                     strides=[2,2],\n",
    "                                     padding=\"VALID\"\n",
    "                                     kernel_initializer=tf.initializers.contrib.layers.xavier_initializer_conv2d, \n",
    "                                     name=\"conv2\")\n",
    "            \n",
    "            self._conv2_batch = tf.layers.batch_normalization(self._conv2,trainable=True,name=\"b_conv2\")\n",
    "            self._conv2_out = tf.nn.elu(self._conv2_batch,name = \"e_conv2\")\n",
    "            \n",
    "            self._conv3 = tf.layers.conv2d(self._conv2_out,\n",
    "                                     filters=128,\n",
    "                                     kernel_size=[4,4],\n",
    "                                     strides=[2,2],\n",
    "                                     padding=\"VALID\"\n",
    "                                     kernel_initializer=tf.initializers.contrib.layers.xavier_initializer_conv2d, \n",
    "                                     name=\"conv3\")\n",
    "            \n",
    "            self._conv3_batch = tf.layers.batch_normalization(self._conv3,trainable=True,name=\"b_conv3\")\n",
    "            self._conv3_out = tf.nn.elu(self._conv3_batch,name = \"e_conv3\")\n",
    "            \n",
    "            \n",
    "            self._flat = tf.layers.flatten(self._conv3_out,name=\"flat\")\n",
    "            \n",
    "            self._dense1 = tf.layers.dense(self._flat,\n",
    "                            units=512,\n",
    "                            activation=tf.nn.elu,\n",
    "                            kernel_initializer=tf.initializers.contrib.layers.xavier_initializer_conv2d)\n",
    "             \n",
    "            self._out = tf.layers.dense(self._dense1,\n",
    "                            units=512,\n",
    "                            kernel_initializer=tf.initializers.contrib.layers.xavier_initializer_conv2d)\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
